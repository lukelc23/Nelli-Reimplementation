{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed\n",
    "v3 = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nellinetworkconjunctive\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)  \n",
    "\n",
    "from nellinetworkconjunctive_proportion_v3 import Network\n",
    "from helpers import fit_sigmoid, mean_squared_error, rotate, load_behavioural_data\n",
    "from plotting import plotting_init, matrix_plot, mds_plot\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load behavioural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midd_performance, high_performers, low_performers = load_behavioural_data(\"../behavioural-data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set simulation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"main\" # \"lazy-regime\", \"two-readouts\", \"fixed-inputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "seeds_n = 10\n",
    "mds_seed = 1\n",
    "\n",
    "# Number of input items\n",
    "items_n = 7\n",
    "\n",
    "# Experiment details\n",
    "training_blocks = 1\n",
    "trials = 2000\n",
    "training_length = training_blocks * trials\n",
    "# stitching_steps = 20\n",
    "\n",
    "# Network hyperparameters\n",
    "readouts = 2 if mode == \"two-readouts\" else 1\n",
    "h1_size = 20\n",
    "\n",
    "if mode == \"lazy-regime\":\n",
    "    w1_weight_std = np.sqrt(6. / items_n)\n",
    "    w2_weight_std = np.sqrt(10. / h1_size)\n",
    "else:\n",
    "    w1_weight_std = 0.025 * np.sqrt(1 / items_n)\n",
    "    w2_weight_std = np.sqrt(1 / h1_size)\n",
    "\n",
    "learning_rate = 0.03 if mode == \"lazy-regime\" else 0.05\n",
    "learning_rate_layers_3_4 = 0.05\n",
    "\n",
    "# Parameter space for gridsearch\n",
    "gammas = np.concatenate([[0], np.geomspace(1e-4, 1, 69)])\n",
    "ss = np.geomspace(1e-2, 100, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TI Exp with conjunctive population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_networks_exp(gamma):\n",
    "    # Log\n",
    "    results = {\n",
    "        \"train\": {\n",
    "            \"losses\": np.zeros((seeds_n, training_length)),\n",
    "            \"w1s\": np.zeros((seeds_n, training_length, h1_size, items_n)),\n",
    "            \"w2s\": np.zeros((seeds_n, training_length, readouts, h1_size)),\n",
    "            \"h1s\": np.zeros((seeds_n, training_length, items_n, h1_size)),\n",
    "            \"certainties\": np.zeros((seeds_n, training_length, items_n, items_n)),\n",
    "            \"evals\": np.zeros((seeds_n, items_n, items_n)),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    results[\"train\"][\"training_progress\"] = np.zeros((seeds_n, training_length, items_n, items_n))\n",
    "    \n",
    "    for seed in range(seeds_n):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Init Network\n",
    "        model = Network(items_n, h1_size, w1_weight_std, w2_weight_std, readouts=readouts)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimiser = torch.optim.SGD([\n",
    "            {'params': [*model.layer_1.parameters(), *model.layer_2.parameters()], 'lr': learning_rate},\n",
    "            {'params': [*model.layer_3.parameters(), *model.layer_4.parameters()], 'lr': learning_rate_layers_3_4}\n",
    "        ])\n",
    "\n",
    "        training_step = 0\n",
    "        items_per_context = items_n\n",
    "        \n",
    "        for block in range(training_blocks): \n",
    "            items_per_context = 7\n",
    "            p = 4\n",
    "            q = 2\n",
    "            training_pairs_norm = np.asarray(list(zip(range(0, items_per_context - 1), range(1, items_per_context))))\n",
    "            training_pairs_exp = np.asarray([[p,q]])\n",
    "            training_pairs = np.concatenate([training_pairs_norm, training_pairs_exp], axis=0)\n",
    "            for trial in range(trials):\n",
    "                # Sample input and target\n",
    "                random_index = np.random.randint(0, len(training_pairs))\n",
    "                item_1, item_2 = np.random.choice(training_pairs[random_index], 2, False)\n",
    "                if readouts == 1:\n",
    "                    if item_1 == p and item_2 == q or item_1 == q and item_2 == p:\n",
    "                        exception = True\n",
    "                    else:\n",
    "                        exception = False\n",
    "                    if not exception:\n",
    "                        target = torch.tensor([1. if item_1 > item_2 else -1.])\n",
    "                    else:\n",
    "                        target = torch.tensor([-1. if item_1 > item_2 else 1.])\n",
    "\n",
    "                #UNCHANGED SO FAR\n",
    "                elif readouts == 2:\n",
    "                    target = torch.tensor([1., -1.] if item_1 > item_2 else [-1., 1.])\n",
    "\n",
    "\n",
    "                # Forward propagate and backpropagate\n",
    "                optimiser.zero_grad()\n",
    "                _, output = model(item_1, item_2)\n",
    "                model.loss = criterion(output, target)\n",
    "                model.loss.backward()\n",
    "                model.correct(learning_rate, gamma)\n",
    "                optimiser.step()\n",
    "\n",
    "                # Log\n",
    "                with torch.no_grad():\n",
    "                    results[\"train\"][\"losses\"][seed, training_step] = model.loss.item()\n",
    "                    results[\"train\"][\"w1s\"][seed, training_step] = model.layer_1.weight.detach().numpy().copy()\n",
    "                    results[\"train\"][\"w2s\"][seed, training_step] = model.layer_2.weight.detach().numpy().copy()\n",
    "                    results[\"train\"][\"h1s\"][seed, training_step] = model.extract_h1s()\n",
    "                    results[\"train\"][\"certainties\"][seed, training_step] = model.pairwise_certainty.a.copy()\n",
    "                    results[\"train\"][\"training_progress\"][seed, training_step] = model.evaluate()\n",
    "                \n",
    "                training_step += 1\n",
    "        \n",
    "        # Evaluate\n",
    "        with torch.no_grad():\n",
    "            results[\"train\"][\"evals\"][seed] = model.evaluate()\n",
    "        \n",
    "    return gamma, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_networks_exp(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the average loss across all seeds during training\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "losses = results[\"train\"][\"losses\"]  # shape: (seeds_n, training_steps)\n",
    "avg_loss = losses.mean(axis=0)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(avg_loss, label='Average Loss')\n",
    "plt.xlabel(\"Training Time Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Average Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for every possible pair (i, j) in different figures\n",
    "# If results is a tuple, unpack it to get the actual results dict\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "training_progress = results[\"train\"][\"training_progress\"]\n",
    "seeds_n = training_progress.shape[0]\n",
    "items_n = training_progress.shape[2]\n",
    "\n",
    "for i in range(items_n):\n",
    "    for j in range(items_n):\n",
    "        if i == j:\n",
    "            continue  # skip diagonal if desired\n",
    "        plt.figure(figsize=(7,4))\n",
    "        for seed in range(seeds_n):\n",
    "            plt.plot(training_progress[seed, :480, i, j], alpha=0.5)\n",
    "        plt.xlabel(\"Training Time Steps\")\n",
    "        plt.ylabel(\"Margin\")\n",
    "        plt.title(f\"Pair ({i}, {j})\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average margin across seeds and time for each (i, j) pair\n",
    "# Resulting in a grid of shape (items_n, items_n)\n",
    "t_final = training_progress.shape[1] - 1\n",
    "average_margin_grid = training_progress[:, t_final, :, :].mean(axis=0)\n",
    "print(\"Average margin grid (across seeds and final time):\")\n",
    "print(average_margin_grid)\n",
    "\n",
    "# Plot the average margin grid as a heatmap with values over each rectangle\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(average_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im, label=\"Average Margin\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.title(\"Average Margin Grid Across Seeds and Time\")\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(average_margin_grid.shape[0]):\n",
    "    for j in range(average_margin_grid.shape[1]):\n",
    "        value = average_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"correct\" average margin grid where (4,2) and (2,4) entries are multiplied by -1, as well as if i>j\n",
    "correct_margin_grid = average_margin_grid.copy()\n",
    "correct_margin_grid[4, 2] *= -1\n",
    "correct_margin_grid[2, 4] *= -1\n",
    "for i in range(correct_margin_grid.shape[0]):\n",
    "    for j in range(correct_margin_grid.shape[1]):\n",
    "        if i>j and ( (i != 2 and j != 4) or (i != 4 and j != 2) ):\n",
    "            correct_margin_grid[i,j] *= -1\n",
    "\n",
    "print(\"Corrected average margin grid:\")\n",
    "print(correct_margin_grid)\n",
    "\n",
    "# Plot the corrected average margin grid as a heatmap with values over each rectangle\n",
    "plt.figure(figsize=(6, 5))\n",
    "im_correct = plt.imshow(correct_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im_correct, label=\"Corrected Average Margin\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.suptitle(\"Corrected Average Margin Grid (Flipped (4,2) and (2,4))\")\n",
    "plt.title(\"conjunctive_small_lr copy\")\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(correct_margin_grid.shape[0]):\n",
    "    for j in range(correct_margin_grid.shape[1]):\n",
    "        value = correct_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im_correct.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sigmoid of the corrected average margin grid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid_correct_margin_grid = sigmoid(correct_margin_grid)\n",
    "\n",
    "print(\"Sigmoid of corrected average margin grid:\")\n",
    "print(sigmoid_correct_margin_grid)\n",
    "\n",
    "# Plot the sigmoid margin grid as a heatmap with values in each cell\n",
    "plt.figure(figsize=(6, 5))\n",
    "im_sigmoid_correct = plt.imshow(sigmoid_correct_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im_sigmoid_correct, label=\"Sigmoid(Corrected Average Margin)\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.suptitle(\"Sigmoid of Corrected Average Margin Grid\")\n",
    "plt.title(\"conjunctive_small_lr_copy\", color='gray')\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(sigmoid_correct_margin_grid.shape[0]):\n",
    "    for j in range(sigmoid_correct_margin_grid.shape[1]):\n",
    "        value = sigmoid_correct_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im_sigmoid_correct.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set your training pair (ensure p, q are defined as desired)\n",
    "p, q = 4, 2\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "\n",
    "# Masks: only (p,q) and (q,p) are training; test = all other off-diagonals\n",
    "non_diag = ~np.eye(items_n, dtype=bool)\n",
    "train_mask = np.zeros((items_n, items_n), dtype=bool)\n",
    "train_mask[p, q] = True\n",
    "train_mask[q, p] = True\n",
    "test_mask = non_diag & ~train_mask\n",
    "\n",
    "train_vals = correct_margin_grid[train_mask]\n",
    "test_vals = correct_margin_grid[test_mask]\n",
    "\n",
    "# Jittered x-positions for scatter\n",
    "rng = np.random.default_rng(0)\n",
    "x_train = rng.normal(loc=0, scale=0.05, size=train_vals.size)\n",
    "x_test  = rng.normal(loc=1, scale=0.05, size=test_vals.size)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(x_train, train_vals, color='C0', alpha=0.9, label='Train')\n",
    "plt.scatter(x_test,  test_vals,  color='C1', alpha=0.6, label='Test')\n",
    "\n",
    "# Optional: overlay means\n",
    "plt.hlines(train_vals.mean(), -0.2, 0.2, colors='C0', linestyles='--', linewidth=2)\n",
    "plt.hlines(test_vals.mean(),  0.8,  1.2, colors='C1', linestyles='--', linewidth=2)\n",
    "\n",
    "plt.xticks([0, 1], ['Train', 'Test'])\n",
    "plt.ylabel('Average margin')\n",
    "plt.title(f'Average Pair Margins at Final Time Step (Train: ({p},{q})/({q},{p}))')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.4, 1.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of TEST pair margins grouped by symbolic distance |i - j|\n",
    "# Assumes: correct_margin_grid, t_final, p, q are defined as above\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "# Exclude diagonal and training pair (p,q)/(q,p)\n",
    "non_diag = ~np.eye(items_n, dtype=bool)\n",
    "train_mask = np.zeros((items_n, items_n), dtype=bool)\n",
    "train_mask[p, q] = True\n",
    "train_mask[q, p] = True\n",
    "test_mask = non_diag & ~train_mask\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for d in range(1, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & test_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, label=None)\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "plt.xticks(range(1, items_n), [str(d) for d in range(1, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j|')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title(f'Test Pair Margins by Symbolic Distance (Train excluded: ({p},{q})/({q},{p}))')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(0.5, items_n - 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of TEST pair margins grouped by symbolic distance |i - j|, including sd=0\n",
    "# Assumes: correct_margin_grid, t_final, p, q are defined\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "# Training = all sd==1 pairs + the special pair (p,q)/(q,p)\n",
    "training_mask = (dist_mat == 1)\n",
    "training_mask[p, q] = True\n",
    "training_mask[q, p] = True\n",
    "\n",
    "# Test = everything else (including diagonal sd=0)\n",
    "test_mask = ~training_mask\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for d in range(0, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & test_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18)\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (test only, includes sd=0)')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title(f'Test Pair Margins by Symbolic Distance (Train: sd=1 and ({p},{q})/({q},{p}) excluded)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of pair margins by symbolic distance |i - j| (including sd=0),\n",
    "# highlighting the exception pair (p,q)/(q,p) with a distinct color and label.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Exclude the exception pair from the base scatter to avoid duplicate markers\n",
    "base_mask = np.ones_like(dist_mat, dtype=bool)\n",
    "base_mask[p, q] = False\n",
    "base_mask[q, p] = False\n",
    "\n",
    "# Plot all pairs grouped by symbolic distance (including sd=0 and sd=1)\n",
    "for d in range(0, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & base_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, color='C0')\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "# Highlight the exception pair (p,q) and (q,p) at their symbolic distance\n",
    "d_exc = abs(p - q)\n",
    "y_pq = correct_margin_grid[p, q]\n",
    "y_qp = correct_margin_grid[q, p]\n",
    "plt.scatter(d_exc - 0.12, y_pq, color='crimson', marker='*', s=140, zorder=5, label=f'Exception ({p},{q})')\n",
    "plt.scatter(d_exc + 0.12, y_qp, color='crimson', marker='*', s=140, zorder=5)\n",
    "\n",
    "# Annotate the exception points\n",
    "plt.annotate(f'({p},{q})', (d_exc - 0.12, y_pq), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "plt.annotate(f'({q},{p})', (d_exc + 0.12, y_qp), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (all pairs)')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title('Pair Margins by Symbolic Distance (exception highlighted)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of pair margins by symbolic distance |i - j| (including sd=0),\n",
    "# highlighting the exception pair (p,q)/(q,p) using sigmoid_correct_margin_grid.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = sigmoid_correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Exclude the exception pair from the base scatter to avoid duplicate markers\n",
    "base_mask = np.ones_like(dist_mat, dtype=bool)\n",
    "base_mask[p, q] = False\n",
    "base_mask[q, p] = False\n",
    "\n",
    "# Plot all pairs grouped by symbolic distance (including sd=0 and sd=1)\n",
    "for d in range(0, items_n):\n",
    "    vals = sigmoid_correct_margin_grid[(dist_mat == d) & base_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, color='C0')\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "# Highlight the exception pair (p,q) and (q,p) at their symbolic distance\n",
    "d_exc = abs(p - q)\n",
    "y_pq = sigmoid_correct_margin_grid[p, q]\n",
    "y_qp = sigmoid_correct_margin_grid[q, p]\n",
    "plt.scatter(d_exc - 0.12, y_pq, color='crimson', marker='*', s=140, zorder=5, label=f'Exception ({p},{q})')\n",
    "plt.scatter(d_exc + 0.12, y_qp, color='crimson', marker='*', s=140, zorder=5)\n",
    "\n",
    "# Annotate the exception points\n",
    "plt.annotate(f'({p},{q})', (d_exc - 0.12, y_pq), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "plt.annotate(f'({q},{p})', (d_exc + 0.12, y_qp), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (all pairs)')\n",
    "plt.ylabel('Sigmoid-corrected average margin (t = %d)' % t_final)\n",
    "plt.title('Pair Margins by Symbolic Distance (exception highlighted)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Extract training pair results and save to CSV\n",
    "# We'll save the average margin over seeds for each pair (i, j) at each time step\n",
    "\n",
    "# If results is a tuple, unpack it to get the actual results dict\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "training_progress = results[\"train\"][\"training_progress\"]  # shape: (seeds_n, time_steps, items_n, items_n)\n",
    "seeds_n, time_steps, items_n, _ = training_progress.shape\n",
    "\n",
    "# Prepare CSV header\n",
    "header = [\"time_step\", \"i\", \"j\"] + [f\"seed_{seed}\" for seed in range(seeds_n)] + [\"mean_margin\", \"std_margin\"]\n",
    "\n",
    "rows = []\n",
    "for i in range(items_n):\n",
    "    for j in range(items_n):\n",
    "        for t in range(time_steps):\n",
    "            margins = training_progress[:, t, i, j]\n",
    "            mean_margin = margins.mean()\n",
    "            std_margin = margins.std()\n",
    "            row = [t, i, j] + list(margins) + [mean_margin, std_margin]\n",
    "            rows.append(row)\n",
    "\n",
    "# Write to CSV\n",
    "# 'network' here refers to a variable defined earlier in the notebook, not to the class 'nellinetwork'.\n",
    "csv_filename = f\"training_pair_margins_conjunctive_small_lr_copy.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Training pair results saved to {csv_filename}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with training pair margins\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Display the first few rows to verify extraction\n",
    "print(\"Extracted results from CSV:\")\n",
    "print(df.head())\n",
    "\n",
    "# Now 'df' contains the extracted results and can be used for further analysis or plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out keyerror on t issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Try to find the correct time, i, j column names\n",
    "# The original code expects 't', but the CSV uses 'time_step'\n",
    "# Let's map accordingly\n",
    "col_map = {}\n",
    "for col in df.columns:\n",
    "    if col.lower() in ['t', 'time', 'time_step']:\n",
    "        col_map['t'] = col\n",
    "    if col.lower() == 'i':\n",
    "        col_map['i'] = col\n",
    "    if col.lower() == 'j':\n",
    "        col_map['j'] = col\n",
    "\n",
    "# Use mapped column names\n",
    "t_col = col_map.get('t', 'time_step')\n",
    "i_col = col_map.get('i', 'i')\n",
    "j_col = col_map.get('j', 'j')\n",
    "\n",
    "df_sorted = df.sort_values([t_col, i_col, j_col]).reset_index(drop=True)\n",
    "\n",
    "# The number of margin columns is seeds_n\n",
    "margin_cols = [col for col in df.columns if col not in [t_col, i_col, j_col, 'mean_margin', 'std_margin']]\n",
    "seeds_n = len(margin_cols)\n",
    "time_steps = df[t_col].max() + 1  # assumes t is 0-based and contiguous\n",
    "items_n = max(df[i_col].max(), df[j_col].max()) + 1  # assuming 0-based indexing\n",
    "\n",
    "# Initialize training_progress array\n",
    "training_progress = np.zeros((seeds_n, time_steps, items_n, items_n))\n",
    "\n",
    "# Fill the array\n",
    "for idx, row in df.iterrows():\n",
    "    t = int(row[t_col])\n",
    "    i = int(row[i_col])\n",
    "    j = int(row[j_col])\n",
    "    for s, col in enumerate(margin_cols):\n",
    "        training_progress[s, t, i, j] = row[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_context = 7\n",
    "p = 4\n",
    "q = 2\n",
    "\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "n = items_n\n",
    "Grid = np.zeros((seeds_n, n, n))\n",
    "for seed in range(seeds_n):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Grid[seed, i, j] = training_progress[seed, training_progress.shape[1]-1, i, j]\n",
    "Average_Grid = np.mean(Grid, axis=0)\n",
    "Std_Grid = np.var(Grid, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Average_Grid, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Mean Margin')\n",
    "plt.title(f'Mean Margin Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "\n",
    "# Plot mean numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Average_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Std_Grid, cmap='magma', interpolation='none')\n",
    "plt.colorbar(label='Variance of Margin')\n",
    "plt.title(f'Variance Margin Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot variance numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Std_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isinstance(results, tuple):\n",
    "    # results = results[1]\n",
    "# training_progress = results[\"train\"][\"training_progress\"]\n",
    "n = items_n\n",
    "Grid = np.zeros((seeds_n, n, n))\n",
    "for seed in range(seeds_n):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Grid[seed, i, j] = training_progress[seed, training_length - 1, i, j]\n",
    "Average_Grid = np.mean(Grid, axis=0)\n",
    "# Apply sigmoid function to Average_Grid\n",
    "Average_Grid = 1 / (1 + np.exp(-Average_Grid))\n",
    "Std_Grid = np.var(Grid, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Average_Grid, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Mean Margin')\n",
    "plt.title(f'Mean Sigmoid(Margin) Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot mean numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Average_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Std_Grid, cmap='magma', interpolation='none')\n",
    "plt.colorbar(label='Variance of Margin')\n",
    "plt.title('Variance Grid for TI exp on Nelli Conjunctive Network')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot variance numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Std_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env (tiexp)",
   "language": "python",
   "name": "tiexp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
