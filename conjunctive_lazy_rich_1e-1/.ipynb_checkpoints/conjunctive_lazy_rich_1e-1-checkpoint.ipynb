{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed\n",
    "v3 = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nellinetworkconjunctive\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)  \n",
    "\n",
    "from nellinetworkconjunctivev2 import Network\n",
    "from helpers import fit_sigmoid, mean_squared_error, rotate, load_behavioural_data\n",
    "from plotting import plotting_init, matrix_plot, mds_plot\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load behavioural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midd_performance, high_performers, low_performers = load_behavioural_data(\"../behavioural-data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set simulation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"main\" # \"lazy-regime\", \"two-readouts\", \"fixed-inputs\"\n",
    "mode2 = \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "seeds_n = 10\n",
    "mds_seed = 1\n",
    "\n",
    "# Number of input items\n",
    "items_n = 7\n",
    "\n",
    "# Experiment details\n",
    "training_blocks = 1\n",
    "trials = 2000\n",
    "training_length = training_blocks * trials\n",
    "# stitching_steps = 20\n",
    "\n",
    "# Network hyperparameters\n",
    "readouts = 2 if mode == \"two-readouts\" else 1\n",
    "h1_size = 20\n",
    "\n",
    "if mode == \"lazy-regime\":\n",
    "    w1_weight_std = np.sqrt(6. / items_n)\n",
    "    w2_weight_std = np.sqrt(10. / h1_size)\n",
    "else:\n",
    "    w1_weight_std = 0.025 * np.sqrt(1 / items_n)\n",
    "    w2_weight_std = np.sqrt(1 / h1_size)\n",
    "\n",
    "proportion = 10    \n",
    "    \n",
    "if mode2 == \"lazy-regime\":\n",
    "    w3_weight_std = np.sqrt(6. / items_n)\n",
    "    w4_weight_std = np.sqrt(10. / h1_size)\n",
    "else:\n",
    "    w3_weight_std = 0.025 * np.sqrt(1 / items_n) / proportion\n",
    "    w4_weight_std = np.sqrt(1 / h1_size) / proportion\n",
    "\n",
    "learning_rate = 0.03 if mode == \"lazy-regime\" else 0.05\n",
    "learning_rate_layers_3_4 = 0.05\n",
    "\n",
    "# Parameter space for gridsearch\n",
    "gammas = np.concatenate([[0], np.geomspace(1e-4, 1, 69)])\n",
    "ss = np.geomspace(1e-2, 100, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00944911182523068\n",
      "0.000944911182523068\n"
     ]
    }
   ],
   "source": [
    "print(w1_weight_std)\n",
    "print(w3_weight_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TI Exp with conjunctive population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_networks_exp(gamma):\n",
    "    # Log\n",
    "    results = {\n",
    "        \"train\": {\n",
    "            \"losses\": np.zeros((seeds_n, training_length)),\n",
    "            \"w1s\": np.zeros((seeds_n, training_length, h1_size, items_n)),\n",
    "            \"w2s\": np.zeros((seeds_n, training_length, readouts, h1_size)),\n",
    "            \"h1s\": np.zeros((seeds_n, training_length, items_n, h1_size)),\n",
    "            \"certainties\": np.zeros((seeds_n, training_length, items_n, items_n)),\n",
    "            \"evals\": np.zeros((seeds_n, items_n, items_n)),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    results[\"train\"][\"training_progress\"] = np.zeros((seeds_n, training_length, items_n, items_n))\n",
    "    \n",
    "    for seed in range(seeds_n):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Init Network\n",
    "        model = Network(items_n, h1_size, w1_weight_std, w2_weight_std, w3_weight_std, w4_weight_std, readouts=readouts)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimiser = torch.optim.SGD([\n",
    "            {'params': [*model.layer_1.parameters(), *model.layer_2.parameters()], 'lr': learning_rate},\n",
    "            {'params': [*model.layer_3.parameters(), *model.layer_4.parameters()], 'lr': learning_rate_layers_3_4}\n",
    "        ])\n",
    "\n",
    "        training_step = 0\n",
    "        items_per_context = items_n\n",
    "        \n",
    "        for block in range(training_blocks): \n",
    "            items_per_context = 7\n",
    "            p = 4\n",
    "            q = 2\n",
    "            training_pairs_norm = np.asarray(list(zip(range(0, items_per_context - 1), range(1, items_per_context))))\n",
    "            training_pairs_exp = np.asarray([[p,q]])\n",
    "            training_pairs = np.concatenate([training_pairs_norm, training_pairs_exp], axis=0)\n",
    "            for trial in range(trials):\n",
    "                # Sample input and target\n",
    "                random_index = np.random.randint(0, len(training_pairs))\n",
    "                item_1, item_2 = np.random.choice(training_pairs[random_index], 2, False)\n",
    "                if readouts == 1:\n",
    "                    if item_1 == p and item_2 == q or item_1 == q and item_2 == p:\n",
    "                        exception = True\n",
    "                    else:\n",
    "                        exception = False\n",
    "                    if not exception:\n",
    "                        target = torch.tensor([1. if item_1 > item_2 else -1.])\n",
    "                    else:\n",
    "                        target = torch.tensor([-1. if item_1 > item_2 else 1.])\n",
    "\n",
    "                #UNCHANGED SO FAR\n",
    "                elif readouts == 2:\n",
    "                    target = torch.tensor([1., -1.] if item_1 > item_2 else [-1., 1.])\n",
    "\n",
    "\n",
    "                # Forward propagate and backpropagate\n",
    "                optimiser.zero_grad()\n",
    "                _, output = model(item_1, item_2)\n",
    "                model.loss = criterion(output, target)\n",
    "                model.loss.backward()\n",
    "                model.correct(learning_rate, gamma)\n",
    "                optimiser.step()\n",
    "\n",
    "                # Log\n",
    "                with torch.no_grad():\n",
    "                    results[\"train\"][\"losses\"][seed, training_step] = model.loss.item()\n",
    "                    results[\"train\"][\"w1s\"][seed, training_step] = model.layer_1.weight.detach().numpy().copy()\n",
    "                    results[\"train\"][\"w2s\"][seed, training_step] = model.layer_2.weight.detach().numpy().copy()\n",
    "                    results[\"train\"][\"h1s\"][seed, training_step] = model.extract_h1s()\n",
    "                    results[\"train\"][\"certainties\"][seed, training_step] = model.pairwise_certainty.a.copy()\n",
    "                    results[\"train\"][\"training_progress\"][seed, training_step] = model.evaluate()\n",
    "                \n",
    "                training_step += 1\n",
    "        \n",
    "        # Evaluate\n",
    "        with torch.no_grad():\n",
    "            results[\"train\"][\"evals\"][seed] = model.evaluate()\n",
    "        \n",
    "    return gamma, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_networks_exp(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the average loss across all seeds during training\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "losses = results[\"train\"][\"losses\"]  # shape: (seeds_n, training_steps)\n",
    "avg_loss = losses.mean(axis=0)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(avg_loss, label='Average Loss')\n",
    "plt.xlabel(\"Training Time Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Average Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for every possible pair (i, j) in different figures\n",
    "# If results is a tuple, unpack it to get the actual results dict\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "training_progress = results[\"train\"][\"training_progress\"]\n",
    "seeds_n = training_progress.shape[0]\n",
    "items_n = training_progress.shape[2]\n",
    "\n",
    "for i in range(items_n):\n",
    "    for j in range(items_n):\n",
    "        if i == j:\n",
    "            continue  # skip diagonal if desired\n",
    "        plt.figure(figsize=(7,4))\n",
    "        for seed in range(seeds_n):\n",
    "            plt.plot(training_progress[seed, :480, i, j], alpha=0.5)\n",
    "        plt.xlabel(\"Training Time Steps\")\n",
    "        plt.ylabel(\"Margin\")\n",
    "        plt.title(f\"Pair ({i}, {j})\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average margin across seeds and time for each (i, j) pair\n",
    "# Resulting in a grid of shape (items_n, items_n)\n",
    "t_final = training_progress.shape[1] - 1\n",
    "average_margin_grid = training_progress[:, t_final, :, :].mean(axis=0)\n",
    "print(\"Average margin grid (across seeds and final time):\")\n",
    "print(average_margin_grid)\n",
    "\n",
    "# Plot the average margin grid as a heatmap with values over each rectangle\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(average_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im, label=\"Average Margin\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.title(\"Average Margin Grid Across Seeds and Time\")\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(average_margin_grid.shape[0]):\n",
    "    for j in range(average_margin_grid.shape[1]):\n",
    "        value = average_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"correct\" average margin grid where (4,2) and (2,4) entries are multiplied by -1, as well as if i>j\n",
    "correct_margin_grid = average_margin_grid.copy()\n",
    "correct_margin_grid[4, 2] *= -1\n",
    "correct_margin_grid[2, 4] *= -1\n",
    "for i in range(correct_margin_grid.shape[0]):\n",
    "    for j in range(correct_margin_grid.shape[1]):\n",
    "        if i>j and ( (i != 2 and j != 4) or (i != 4 and j != 2) ):\n",
    "            correct_margin_grid[i,j] *= -1\n",
    "\n",
    "print(\"Corrected average margin grid:\")\n",
    "print(correct_margin_grid)\n",
    "\n",
    "# Plot the corrected average margin grid as a heatmap with values over each rectangle\n",
    "plt.figure(figsize=(6, 5))\n",
    "im_correct = plt.imshow(correct_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im_correct, label=\"Corrected Average Margin\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.suptitle(\"Corrected Average Margin Grid (Flipped (4,2) and (2,4))\")\n",
    "plt.title(\"conjunctive_small_lr copy\")\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(correct_margin_grid.shape[0]):\n",
    "    for j in range(correct_margin_grid.shape[1]):\n",
    "        value = correct_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im_correct.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sigmoid of the corrected average margin grid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid_correct_margin_grid = sigmoid(correct_margin_grid)\n",
    "\n",
    "print(\"Sigmoid of corrected average margin grid:\")\n",
    "print(sigmoid_correct_margin_grid)\n",
    "\n",
    "# Plot the sigmoid margin grid as a heatmap with values in each cell\n",
    "plt.figure(figsize=(6, 5))\n",
    "im_sigmoid_correct = plt.imshow(sigmoid_correct_margin_grid, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(im_sigmoid_correct, label=\"Sigmoid(Corrected Average Margin)\")\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(\"i\")\n",
    "plt.suptitle(\"Sigmoid of Corrected Average Margin Grid\")\n",
    "plt.title(\"conjunctive_small_lr_copy\", color='gray')\n",
    "\n",
    "# Add values in each cell\n",
    "for i in range(sigmoid_correct_margin_grid.shape[0]):\n",
    "    for j in range(sigmoid_correct_margin_grid.shape[1]):\n",
    "        value = sigmoid_correct_margin_grid[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white' if im_sigmoid_correct.norm(value) < 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set your training pair (ensure p, q are defined as desired)\n",
    "p, q = 4, 2\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "\n",
    "# Masks: only (p,q) and (q,p) are training; test = all other off-diagonals\n",
    "non_diag = ~np.eye(items_n, dtype=bool)\n",
    "train_mask = np.zeros((items_n, items_n), dtype=bool)\n",
    "train_mask[p, q] = True\n",
    "train_mask[q, p] = True\n",
    "test_mask = non_diag & ~train_mask\n",
    "\n",
    "train_vals = correct_margin_grid[train_mask]\n",
    "test_vals = correct_margin_grid[test_mask]\n",
    "\n",
    "# Jittered x-positions for scatter\n",
    "rng = np.random.default_rng(0)\n",
    "x_train = rng.normal(loc=0, scale=0.05, size=train_vals.size)\n",
    "x_test  = rng.normal(loc=1, scale=0.05, size=test_vals.size)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(x_train, train_vals, color='C0', alpha=0.9, label='Train')\n",
    "plt.scatter(x_test,  test_vals,  color='C1', alpha=0.6, label='Test')\n",
    "\n",
    "# Optional: overlay means\n",
    "plt.hlines(train_vals.mean(), -0.2, 0.2, colors='C0', linestyles='--', linewidth=2)\n",
    "plt.hlines(test_vals.mean(),  0.8,  1.2, colors='C1', linestyles='--', linewidth=2)\n",
    "\n",
    "plt.xticks([0, 1], ['Train', 'Test'])\n",
    "plt.ylabel('Average margin')\n",
    "plt.title(f'Average Pair Margins at Final Time Step (Train: ({p},{q})/({q},{p}))')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.4, 1.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of TEST pair margins grouped by symbolic distance |i - j|\n",
    "# Assumes: correct_margin_grid, t_final, p, q are defined as above\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "# Exclude diagonal and training pair (p,q)/(q,p)\n",
    "non_diag = ~np.eye(items_n, dtype=bool)\n",
    "train_mask = np.zeros((items_n, items_n), dtype=bool)\n",
    "train_mask[p, q] = True\n",
    "train_mask[q, p] = True\n",
    "test_mask = non_diag & ~train_mask\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for d in range(1, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & test_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, label=None)\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "plt.xticks(range(1, items_n), [str(d) for d in range(1, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j|')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title(f'Test Pair Margins by Symbolic Distance (Train excluded: ({p},{q})/({q},{p}))')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(0.5, items_n - 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of TEST pair margins grouped by symbolic distance |i - j|, including sd=0\n",
    "# Assumes: correct_margin_grid, t_final, p, q are defined\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "# Training = all sd==1 pairs + the special pair (p,q)/(q,p)\n",
    "training_mask = (dist_mat == 1)\n",
    "training_mask[p, q] = True\n",
    "training_mask[q, p] = True\n",
    "\n",
    "# Test = everything else (including diagonal sd=0)\n",
    "test_mask = ~training_mask\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for d in range(0, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & test_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18)\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (test only, includes sd=0)')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title(f'Test Pair Margins by Symbolic Distance (Train: sd=1 and ({p},{q})/({q},{p}) excluded)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of pair margins by symbolic distance |i - j| (including sd=0),\n",
    "# highlighting the exception pair (p,q)/(q,p) with a distinct color and label.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Exclude the exception pair from the base scatter to avoid duplicate markers\n",
    "base_mask = np.ones_like(dist_mat, dtype=bool)\n",
    "base_mask[p, q] = False\n",
    "base_mask[q, p] = False\n",
    "\n",
    "# Plot all pairs grouped by symbolic distance (including sd=0 and sd=1)\n",
    "for d in range(0, items_n):\n",
    "    vals = correct_margin_grid[(dist_mat == d) & base_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, color='C0')\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "# Highlight the exception pair (p,q) and (q,p) at their symbolic distance\n",
    "d_exc = abs(p - q)\n",
    "y_pq = correct_margin_grid[p, q]\n",
    "y_qp = correct_margin_grid[q, p]\n",
    "plt.scatter(d_exc - 0.12, y_pq, color='crimson', marker='*', s=140, zorder=5, label=f'Exception ({p},{q})')\n",
    "plt.scatter(d_exc + 0.12, y_qp, color='crimson', marker='*', s=140, zorder=5)\n",
    "\n",
    "# Annotate the exception points\n",
    "plt.annotate(f'({p},{q})', (d_exc - 0.12, y_pq), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "plt.annotate(f'({q},{p})', (d_exc + 0.12, y_qp), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (all pairs)')\n",
    "plt.ylabel('Corrected average margin (t = %d)' % t_final)\n",
    "plt.title('Pair Margins by Symbolic Distance (exception highlighted)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of pair margins by symbolic distance |i - j| (including sd=0),\n",
    "# highlighting the exception pair (p,q)/(q,p) using sigmoid_correct_margin_grid.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items_n = sigmoid_correct_margin_grid.shape[0]\n",
    "I, J = np.indices((items_n, items_n))\n",
    "dist_mat = np.abs(I - J)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Exclude the exception pair from the base scatter to avoid duplicate markers\n",
    "base_mask = np.ones_like(dist_mat, dtype=bool)\n",
    "base_mask[p, q] = False\n",
    "base_mask[q, p] = False\n",
    "\n",
    "# Plot all pairs grouped by symbolic distance (including sd=0 and sd=1)\n",
    "for d in range(0, items_n):\n",
    "    vals = sigmoid_correct_margin_grid[(dist_mat == d) & base_mask]\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    x = rng.normal(loc=d, scale=0.06, size=vals.size)  # jitter around integer distance\n",
    "    plt.scatter(x, vals, alpha=0.6, s=18, color='C0')\n",
    "    mean_d = vals.mean()\n",
    "    plt.hlines(mean_d, d - 0.25, d + 0.25, colors='k', linestyles='--', linewidth=1)\n",
    "\n",
    "# Highlight the exception pair (p,q) and (q,p) at their symbolic distance\n",
    "d_exc = abs(p - q)\n",
    "y_pq = sigmoid_correct_margin_grid[p, q]\n",
    "y_qp = sigmoid_correct_margin_grid[q, p]\n",
    "plt.scatter(d_exc - 0.12, y_pq, color='crimson', marker='*', s=140, zorder=5, label=f'Exception ({p},{q})')\n",
    "plt.scatter(d_exc + 0.12, y_qp, color='crimson', marker='*', s=140, zorder=5)\n",
    "\n",
    "# Annotate the exception points\n",
    "plt.annotate(f'({p},{q})', (d_exc - 0.12, y_pq), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "plt.annotate(f'({q},{p})', (d_exc + 0.12, y_qp), textcoords='offset points', xytext=(0, 8),\n",
    "             ha='center', color='crimson', fontsize=9)\n",
    "\n",
    "plt.xticks(range(0, items_n), [str(d) for d in range(0, items_n)])\n",
    "plt.xlabel('Symbolic distance |i - j| (all pairs)')\n",
    "plt.ylabel('Sigmoid-corrected average margin (t = %d)' % t_final)\n",
    "plt.title('Pair Margins by Symbolic Distance (exception highlighted)')\n",
    "plt.axhline(0, color='k', linewidth=1, alpha=0.3)\n",
    "plt.xlim(-0.5, items_n - 0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Extract training pair results and save to CSV\n",
    "# We'll save the average margin over seeds for each pair (i, j) at each time step\n",
    "\n",
    "# If results is a tuple, unpack it to get the actual results dict\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "training_progress = results[\"train\"][\"training_progress\"]  # shape: (seeds_n, time_steps, items_n, items_n)\n",
    "seeds_n, time_steps, items_n, _ = training_progress.shape\n",
    "\n",
    "# Prepare CSV header\n",
    "header = [\"time_step\", \"i\", \"j\"] + [f\"seed_{seed}\" for seed in range(seeds_n)] + [\"mean_margin\", \"std_margin\"]\n",
    "\n",
    "rows = []\n",
    "for i in range(items_n):\n",
    "    for j in range(items_n):\n",
    "        for t in range(time_steps):\n",
    "            margins = training_progress[:, t, i, j]\n",
    "            mean_margin = margins.mean()\n",
    "            std_margin = margins.std()\n",
    "            row = [t, i, j] + list(margins) + [mean_margin, std_margin]\n",
    "            rows.append(row)\n",
    "\n",
    "# Write to CSV\n",
    "# 'network' here refers to a variable defined earlier in the notebook, not to the class 'nellinetwork'.\n",
    "csv_filename = f\"conjunctive_lazy_rich.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Training pair results saved to {csv_filename}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with training pair margins\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Display the first few rows to verify extraction\n",
    "print(\"Extracted results from CSV:\")\n",
    "print(df.head())\n",
    "\n",
    "# Now 'df' contains the extracted results and can be used for further analysis or plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out keyerror on t issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Try to find the correct time, i, j column names\n",
    "# The original code expects 't', but the CSV uses 'time_step'\n",
    "# Let's map accordingly\n",
    "col_map = {}\n",
    "for col in df.columns:\n",
    "    if col.lower() in ['t', 'time', 'time_step']:\n",
    "        col_map['t'] = col\n",
    "    if col.lower() == 'i':\n",
    "        col_map['i'] = col\n",
    "    if col.lower() == 'j':\n",
    "        col_map['j'] = col\n",
    "\n",
    "# Use mapped column names\n",
    "t_col = col_map.get('t', 'time_step')\n",
    "i_col = col_map.get('i', 'i')\n",
    "j_col = col_map.get('j', 'j')\n",
    "\n",
    "df_sorted = df.sort_values([t_col, i_col, j_col]).reset_index(drop=True)\n",
    "\n",
    "# The number of margin columns is seeds_n\n",
    "margin_cols = [col for col in df.columns if col not in [t_col, i_col, j_col, 'mean_margin', 'std_margin']]\n",
    "seeds_n = len(margin_cols)\n",
    "time_steps = df[t_col].max() + 1  # assumes t is 0-based and contiguous\n",
    "items_n = max(df[i_col].max(), df[j_col].max()) + 1  # assuming 0-based indexing\n",
    "\n",
    "# Initialize training_progress array\n",
    "training_progress = np.zeros((seeds_n, time_steps, items_n, items_n))\n",
    "\n",
    "# Fill the array\n",
    "for idx, row in df.iterrows():\n",
    "    t = int(row[t_col])\n",
    "    i = int(row[i_col])\n",
    "    j = int(row[j_col])\n",
    "    for s, col in enumerate(margin_cols):\n",
    "        training_progress[s, t, i, j] = row[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_context = 7\n",
    "p = 4\n",
    "q = 2\n",
    "\n",
    "if isinstance(results, tuple):\n",
    "    results = results[1]\n",
    "n = items_n\n",
    "Grid = np.zeros((seeds_n, n, n))\n",
    "for seed in range(seeds_n):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Grid[seed, i, j] = training_progress[seed, training_progress.shape[1]-1, i, j]\n",
    "Average_Grid = np.mean(Grid, axis=0)\n",
    "Std_Grid = np.var(Grid, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Average_Grid, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Mean Margin')\n",
    "plt.title(f'Mean Margin Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "\n",
    "# Plot mean numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Average_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Std_Grid, cmap='magma', interpolation='none')\n",
    "plt.colorbar(label='Variance of Margin')\n",
    "plt.title(f'Variance Margin Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot variance numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Std_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isinstance(results, tuple):\n",
    "    # results = results[1]\n",
    "# training_progress = results[\"train\"][\"training_progress\"]\n",
    "n = items_n\n",
    "Grid = np.zeros((seeds_n, n, n))\n",
    "for seed in range(seeds_n):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Grid[seed, i, j] = training_progress[seed, training_length - 1, i, j]\n",
    "Average_Grid = np.mean(Grid, axis=0)\n",
    "# Apply sigmoid function to Average_Grid\n",
    "Average_Grid = 1 / (1 + np.exp(-Average_Grid))\n",
    "Std_Grid = np.var(Grid, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Average_Grid, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Mean Margin')\n",
    "plt.title(f'Mean Sigmoid(Margin) Grid for TI exp on Nelli Conjunctive Network\\n(items_n={items_n}, exception=({p},{q}))')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot mean numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Average_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(Std_Grid, cmap='magma', interpolation='none')\n",
    "plt.colorbar(label='Variance of Margin')\n",
    "plt.title('Variance Grid for TI exp on Nelli Conjunctive Network')\n",
    "plt.xlabel('Item i')\n",
    "plt.ylabel('Item j')\n",
    "plt.xticks(range(n))\n",
    "plt.yticks(range(n))\n",
    "# Plot variance numbers over each square\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.text(j, i, f\"{Std_Grid[i, j]:.2f}\", ha='center', va='center', color='white' if Average_Grid[i, j] < (Average_Grid.max() / 2) else 'black', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each non-exception item vs each exception item\n",
    "# Exception items: 2, 3, 4 (from p=4, q=2)\n",
    "# Non-exception items: 0, 1, 5, 6\n",
    "\n",
    "# Import MarginExtractor from parent directory\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get the parent directory (where csv_margin.py should be)\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# If csv_margin.py is not in parent_dir, try current directory or set explicit path\n",
    "if not os.path.exists(os.path.join(parent_dir, 'csv_margin.py')):\n",
    "    # Check if it's in the current directory\n",
    "    if os.path.exists(os.path.join(current_dir, 'csv_margin.py')):\n",
    "        parent_dir = current_dir\n",
    "    else:\n",
    "        # Explicitly set to the Nelli Reimplementation directory\n",
    "        parent_dir = r'Z:\\Luke\\Nelli Reimplementation'\n",
    "\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Using directory: {parent_dir}\")\n",
    "print(f\"csv_margin.py exists: {os.path.exists(os.path.join(parent_dir, 'csv_margin.py'))}\")\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "    \n",
    "from csv_margin import MarginExtractor\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file that was already created\n",
    "csv_filename = \"conjunctive_lazy_rich.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Reconstruct training_progress from CSV (same as Cell 27)\n",
    "t_col = 'time_step'\n",
    "i_col = 'i'\n",
    "j_col = 'j'\n",
    "\n",
    "margin_cols = [col for col in df.columns if col not in [t_col, i_col, j_col, 'mean_margin', 'std_margin']]\n",
    "csv_seeds_n = len(margin_cols)\n",
    "csv_time_steps = df[t_col].max() + 1\n",
    "csv_items_n = max(df[i_col].max(), df[j_col].max()) + 1\n",
    "\n",
    "# Initialize training_progress array from CSV\n",
    "training_progress_from_csv = np.zeros((csv_seeds_n, csv_time_steps, csv_items_n, csv_items_n))\n",
    "\n",
    "# Fill the array\n",
    "for idx, row in df.iterrows():\n",
    "    t = int(row[t_col])\n",
    "    i = int(row[i_col])\n",
    "    j = int(row[j_col])\n",
    "    for s, col in enumerate(margin_cols):\n",
    "        training_progress_from_csv[s, t, i, j] = row[col]\n",
    "\n",
    "# Create a mock results dict for MarginExtractor\n",
    "results_from_csv = {\n",
    "    \"train\": {\n",
    "        \"training_progress\": training_progress_from_csv\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create MarginExtractor from CSV data\n",
    "extractor = MarginExtractor(results_from_csv)\n",
    "print(f\"Loaded data from CSV: {csv_seeds_n} seeds, {csv_time_steps} timesteps, {csv_items_n} items\")\n",
    "\n",
    "# Define exception and non-exception items\n",
    "p, q = 4, 2\n",
    "exception_items = list(range(min(p, q), max(p, q) + 1))  # [2, 3, 4]\n",
    "all_items = list(range(items_n))\n",
    "non_exception_items = [i for i in all_items if i not in exception_items]\n",
    "\n",
    "print(f\"Exception items: {exception_items}\")\n",
    "print(f\"Non-exception items: {non_exception_items}\")\n",
    "\n",
    "# Plot each non-exception item against each exception item\n",
    "for non_exc in non_exception_items:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig.suptitle(f\"Item {non_exc} vs Exception Items\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for idx, exc in enumerate(exception_items):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot margin over time for each seed\n",
    "        for seed in range(seeds_n):\n",
    "            # Get margin for (non_exc, exc)\n",
    "            margin_data = extractor.training_progress[seed, :, non_exc, exc]\n",
    "            ax.plot(margin_data, alpha=0.5, linewidth=1)\n",
    "        \n",
    "        # Calculate mean and plot\n",
    "        mean_margin = extractor.training_progress[:, :, non_exc, exc].mean(axis=0)\n",
    "        ax.plot(mean_margin, color='black', linewidth=2, label='Mean', linestyle='--')\n",
    "        \n",
    "        ax.set_xlabel('Training Step')\n",
    "        ax.set_ylabel('Margin')\n",
    "        ax.set_title(f'({non_exc}, {exc})')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axhline(y=0, color='red', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        \n",
    "    axes[0].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot version - showing final margins for non-exception vs exception items\n",
    "# Reuse the same exception/non-exception item definitions\n",
    "\n",
    "# Get final timestep margins\n",
    "final_timestep = extractor.time_steps - 1\n",
    "\n",
    "for non_exc in non_exception_items:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig.suptitle(f\"Item {non_exc} vs Exception Items (Final Margins - Scatterplot)\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for idx, exc in enumerate(exception_items):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get final margins for all seeds for pair (non_exc, exc)\n",
    "        final_margins = extractor.training_progress[:, final_timestep, non_exc, exc]\n",
    "        \n",
    "        # Create scatter plot with seed indices on x-axis\n",
    "        seeds = np.arange(csv_seeds_n)\n",
    "        ax.scatter(seeds, final_margins, s=100, alpha=0.7, c='steelblue', edgecolors='black', linewidth=1)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_margin = final_margins.mean()\n",
    "        ax.axhline(y=mean_margin, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_margin:.3f}')\n",
    "        \n",
    "        # Add zero reference line\n",
    "        ax.axhline(y=0, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Seed')\n",
    "        ax.set_ylabel('Final Margin')\n",
    "        ax.set_title(f'({non_exc}, {exc})')\n",
    "        ax.set_xticks(seeds)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined scatter plot: all non-exception items vs exception items in one figure\n",
    "# X-axis: exception item index (2, 3, 4)\n",
    "# Y-axis: final margin values (one point per seed)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get final timestep margins\n",
    "final_timestep = extractor.time_steps - 1\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Create a 2x2 subplot grid for all non-exception items\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()  # Flatten to easily iterate\n",
    "\n",
    "fig.suptitle('Non-Exception Items vs Exception Items (All Seeds)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Create a plot for each non-exception item\n",
    "for idx, non_exc_item in enumerate(non_exception_items):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for exc in exception_items:\n",
    "        # Get final margins for all seeds for pair (non_exc_item, exc)\n",
    "        final_margins = extractor.training_progress[:, final_timestep, non_exc_item, exc]\n",
    "        \n",
    "        # Correct margins: multiply by -1 if i > j\n",
    "        if non_exc_item > exc:\n",
    "            final_margins = -1 * final_margins\n",
    "        \n",
    "        # Add jitter to x-coordinates for visibility\n",
    "        x = rng.normal(loc=exc, scale=0.06, size=final_margins.size)\n",
    "        ax.scatter(x, final_margins, alpha=0.6, s=60, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Add mean line with label\n",
    "        mean_margin = final_margins.mean()\n",
    "        ax.hlines(mean_margin, exc - 0.25, exc + 0.25, colors='red', linestyles='--', linewidth=2)\n",
    "        ax.text(exc, mean_margin, f'{mean_margin:.2f}', ha='center', va='bottom', fontsize=8, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='red', alpha=0.8))\n",
    "    \n",
    "    ax.set_xticks(exception_items)\n",
    "    ax.set_xticklabels([str(e) for e in exception_items])\n",
    "    ax.set_xlabel('Exception Item')\n",
    "    ax.set_ylabel('Final Margin')\n",
    "    ax.set_title(f'Corrected Margin on Item {non_exc_item} vs Exception Items', fontweight='bold')\n",
    "    ax.axhline(0, color='gray', linewidth=1, linestyle=':', alpha=0.5)\n",
    "    ax.set_xlim(min(exception_items) - 0.5, max(exception_items) + 0.5)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined scatter plot with SIGMOID(corrected margins)\n",
    "# X-axis: exception item index (2, 3, 4)\n",
    "# Y-axis: sigmoid of final margin values (one point per seed)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get final timestep margins\n",
    "final_timestep = extractor.time_steps - 1\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Create a 2x2 subplot grid for all non-exception items\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()  # Flatten to easily iterate\n",
    "\n",
    "fig.suptitle('Non-Exception Items vs Exception Items - Sigmoid(Corrected Margin) (All Seeds)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Create a plot for each non-exception item\n",
    "for idx, non_exc_item in enumerate(non_exception_items):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for exc in exception_items:\n",
    "        # Get final margins for all seeds for pair (non_exc_item, exc)\n",
    "        final_margins = extractor.training_progress[:, final_timestep, non_exc_item, exc]\n",
    "        \n",
    "        # Correct margins: multiply by -1 if i > j\n",
    "        if non_exc_item > exc:\n",
    "            final_margins = -1 * final_margins\n",
    "        \n",
    "        # Apply sigmoid transformation\n",
    "        final_margins_sigmoid = 1 / (1 + np.exp(-final_margins))\n",
    "        \n",
    "        # Add jitter to x-coordinates for visibility\n",
    "        x = rng.normal(loc=exc, scale=0.06, size=final_margins_sigmoid.size)\n",
    "        ax.scatter(x, final_margins_sigmoid, alpha=0.6, s=60, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Add mean line with label\n",
    "        mean_margin = final_margins_sigmoid.mean()\n",
    "        ax.hlines(mean_margin, exc - 0.25, exc + 0.25, colors='red', linestyles='--', linewidth=2)\n",
    "        ax.text(exc, mean_margin, f'{mean_margin:.3f}', ha='center', va='bottom', fontsize=8, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='red', alpha=0.8))\n",
    "    \n",
    "    ax.set_xticks(exception_items)\n",
    "    ax.set_xticklabels([str(e) for e in exception_items])\n",
    "    ax.set_xlabel('Exception Item')\n",
    "    ax.set_ylabel('Sigmoid(Corrected Margin)')\n",
    "    ax.set_title(f'Item {non_exc_item} vs Exception Items', fontweight='bold')\n",
    "    ax.axhline(0.5, color='gray', linewidth=1, linestyle=':', alpha=0.5, label='Decision boundary')\n",
    "    ax.set_xlim(min(exception_items) - 0.5, max(exception_items) + 0.5)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='lower right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env (tiexp)",
   "language": "python",
   "name": "tiexp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
